import { Callout } from 'nextra/components'
import { Steps } from 'nextra/components'

# Quickstart for AI

Use Storacha to store your LLM, RAG knowledge fragments, agent state, outputs and all the rest in a decentralized network of storage nodes.

Storacha can be used to dynamically store data generated by AI Agents, or for storage/retrieval of initial training data, including RAG knowledge as well as intermediate state. Data can be retrieved by AI Agents using [HTTP](../how-to/retrieve.mdx) or over [IPFS via bitswap](https://docs.ipfs.tech/concepts/bitswap/).

<Callout type="info">
  Coming soon: mutable and private data!
</Callout>

To store data from an AI Agent you can use the JS Client, Go Client or the HTTP Bridge (language independent). Either way, your AI Agent is going to need 2 things - an identity (a DID) and a delegation allowing it to store data to a [Space](../how-to/create-space.mdx). **This should be done offline, on your development machine.**

## Generate a DID

Currently the best way to generate a DID (Decentralized Identifier) for your agent is to use the CLI tool:

<Steps>
### Install the CLI tool

Make sure [Node.js](https://nodejs.org) is installed first, then install the CLI tool:

```sh
npm install -g @web3-storage/w3cli
```

### Generate a DID

```sh
w3 key create
```

Output should look something like:

```sh
# did:key:z6Mkh9TtUbFJcUHhMmS9dEbqpBbHPbL9oxg1zziWn1CYCNZ2
MgCb+bRGl02JqlWMPUxCyntxlYj0T/zLtR2tn8LFvw6+Yke0BKAP/OUu2tXpd+tniEoOzB3pxqxHZpRhrZl1UYUeraT0=
```

</Steps>

<Callout type="warning">
  Make a note of the private key (starting `Mg...`). It will be used as an environment variable later. Also note down the public key (starting `did:key:`) as this will be used next to create the delegation.
</Callout>

## Obtain Proofs

Proofs are _delegations_ to your agent enabling it to perform tasks. Currently the best way to obtain proofs that will allow you to interact with the Storacha API is to use the CLI tool:

<Callout>
  If you're new to Storacha, login with GitHub to get a trial developer account with 100MB of free storage!
</Callout>

<Steps>
### Create a Space

If you haven't already, [install the CLI tool](#install-the-cli-tool) and [generate a DID](#generate-a-did).

```sh
w3 space create [NAME]
```

### Delegate Capabilities to Your Agent

```sh
w3 delegation create -c space/blob/add -c space/index/add -c filecoin/offer -c upload/add <AGENT_DID> --base64
```

This will create a delegation with the minimum permissions required for your agent to _write_ to your space. Make sure you use your agent DID, not the DID of the space you just created!

</Steps>

<Callout>
  Make a note of the space DID from above. Your agent will need to reference it later.
</Callout>

## Integrate with an AI Agent

The JS Client, Go Client or HTTP Bridge can be integrated directly in _any_ AI Agent. In client libraries you simply need to load the agent identity (DID) and the delegation you created above.

Instructions for initializing clients with an identity and delegation:

- [JS Client](../how-to/upload.mdx#bring-your-own-delegations)
- [Go Client](../go-w3up.mdx#load-private-key-and-proofs)
- [HTTP Bridge](../how-to/http-bridge.mdx)

We also provide integrations for specific frameworks making it even easier to use Storacha in these environments.

### ElizaOS

ElizaOS is an AI agent operating system for building, deploying, and managing intelligent agents. Storacha provides a plugin that enables agents to interact with a distributed storage network, allowing for file uploads and retrieval.

[View the ElizaOS integration docs](./elizaos.md)

In case you want to access the Storacha Client directly from the agent code, Storacha provides the client integration in TypeScript/JavaScript.
Enable the plugin in the `character` file, and then use the client implementation provided by the plugin e.g:

**Upload**

```js
const storageClient = await getStorageClient(runtime);
if (storageClient) {
    const cid = await storageClient.getStorage().uploadFile(...);
}
```

**Retrieve**

```js
const resp = await storageClient.getContent(cid)
const content = await resp.arrayBuffer()
```

### Model Context Protocol (MCP) Integration

Storacha provides a Model Context Protocol (MCP) server implementation to seamlessly integrate with AI systems that support MCP, such as Claude, GPT-4, and other language models in supported environments like Cursor.

<Steps>
### Set Up MCP Server

First, clone and install the MCP server:

```bash
git clone https://github.com/storacha/mcp-storage-server.git
cd mcp-storage-server
pnpm install
```

### Configure MCP Client

Configure your MCP client (like Cursor) to use the Storacha server by adding this configuration:

```json
{
  "mcpServers": {
    "storacha-storage-server": {
      "command": "node",
      "args": ["./dist/index.js"],
      "env": {
        "MCP_TRANSPORT_MODE": "stdio",
        "PRIVATE_KEY": "your-agent-private-key",
        "DELEGATION": "your-base64-delegation"
      },
      "shell": true,
      "cwd": "./"
    }
  }
}
```

Replace `your-agent-private-key` with the private key you generated earlier and `your-base64-delegation` with the delegation proof from the previous steps.

### MCP Tools Available

Once configured, your AI application can use the following MCP tools to interact with Storacha storage:

-   **upload**: Store files on the Storacha Network with options to specify file content (base64 encoded), filename, and optional parameters like publishing to Filecoin.

-   **retrieve**: Access stored files from the Storacha Network using Content Identifiers (CIDs) in various path formats (CID/filename, /ipfs/CID/filename, or ipfs://CID/filename).

-   **identity**: Get the DIDKey of the configured Storacha Agent, useful for verifying the identity being used for storage operations.

</Steps>

<Callout type="info">
  For detailed MCP integration instructions, advanced options, and examples, see our [MCP Server Guide](./mcp).
</Callout>

<Callout type="info">
  More integrations coming soon!
</Callout>
